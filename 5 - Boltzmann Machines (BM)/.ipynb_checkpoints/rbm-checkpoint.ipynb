{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARJVTOSbuWCa"
   },
   "source": [
    "#Máquinas de Boltzmann Restringidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6YXqpKUvDuo"
   },
   "source": [
    "# Instalamos pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wGyGxkGucCr"
   },
   "outputs": [],
   "source": [
    "#pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cICmNhmFun39"
   },
   "source": [
    "# Clonamos el repositorio para obtener el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "wHQH29tluo7d",
    "outputId": "c453282d-2a54-442b-c60d-7370b392607a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'deeplearning-az'...\n",
      "remote: Enumerating objects: 57, done.\u001b[K\n",
      "remote: Counting objects:   1% (1/57)\u001b[K\r",
      "remote: Counting objects:   3% (2/57)\u001b[K\r",
      "remote: Counting objects:   5% (3/57)\u001b[K\r",
      "remote: Counting objects:   7% (4/57)\u001b[K\r",
      "remote: Counting objects:   8% (5/57)\u001b[K\r",
      "remote: Counting objects:  10% (6/57)\u001b[K\r",
      "remote: Counting objects:  12% (7/57)\u001b[K\r",
      "remote: Counting objects:  14% (8/57)\u001b[K\r",
      "remote: Counting objects:  15% (9/57)\u001b[K\r",
      "remote: Counting objects:  17% (10/57)\u001b[K\r",
      "remote: Counting objects:  19% (11/57)\u001b[K\r",
      "remote: Counting objects:  21% (12/57)\u001b[K\r",
      "remote: Counting objects:  22% (13/57)\u001b[K\r",
      "remote: Counting objects:  24% (14/57)\u001b[K\r",
      "remote: Counting objects:  26% (15/57)\u001b[K\r",
      "remote: Counting objects:  28% (16/57)\u001b[K\r",
      "remote: Counting objects:  29% (17/57)\u001b[K\r",
      "remote: Counting objects:  31% (18/57)\u001b[K\r",
      "remote: Counting objects:  33% (19/57)\u001b[K\r",
      "remote: Counting objects:  35% (20/57)\u001b[K\r",
      "remote: Counting objects:  36% (21/57)\u001b[K\r",
      "remote: Counting objects:  38% (22/57)\u001b[K\r",
      "remote: Counting objects:  40% (23/57)\u001b[K\r",
      "remote: Counting objects:  42% (24/57)\u001b[K\r",
      "remote: Counting objects:  43% (25/57)\u001b[K\r",
      "remote: Counting objects:  45% (26/57)\u001b[K\r",
      "remote: Counting objects:  47% (27/57)\u001b[K\r",
      "remote: Counting objects:  49% (28/57)\u001b[K\r",
      "remote: Counting objects:  50% (29/57)\u001b[K\r",
      "remote: Counting objects:  52% (30/57)\u001b[K\r",
      "remote: Counting objects:  54% (31/57)\u001b[K\r",
      "remote: Counting objects:  56% (32/57)\u001b[K\r",
      "remote: Counting objects:  57% (33/57)\u001b[K\r",
      "remote: Counting objects:  59% (34/57)\u001b[K\r",
      "remote: Counting objects:  61% (35/57)\u001b[K\r",
      "remote: Counting objects:  63% (36/57)\u001b[K\r",
      "remote: Counting objects:  64% (37/57)\u001b[K\r",
      "remote: Counting objects:  66% (38/57)\u001b[K\r",
      "remote: Counting objects:  68% (39/57)\u001b[K\r",
      "remote: Counting objects:  70% (40/57)\u001b[K\r",
      "remote: Counting objects:  71% (41/57)\u001b[K\r",
      "remote: Counting objects:  73% (42/57)\u001b[K\r",
      "remote: Counting objects:  75% (43/57)\u001b[K\r",
      "remote: Counting objects:  77% (44/57)\u001b[K\r",
      "remote: Counting objects:  78% (45/57)\u001b[K\r",
      "remote: Counting objects:  80% (46/57)\u001b[K\r",
      "remote: Counting objects:  82% (47/57)\u001b[K\r",
      "remote: Counting objects:  84% (48/57)\u001b[K\r",
      "remote: Counting objects:  85% (49/57)\u001b[K\r",
      "remote: Counting objects:  87% (50/57)\u001b[K\r",
      "remote: Counting objects:  89% (51/57)\u001b[K\r",
      "remote: Counting objects:  91% (52/57)\u001b[K\r",
      "remote: Counting objects:  92% (53/57)\u001b[K\r",
      "remote: Counting objects:  94% (54/57)\u001b[K\r",
      "remote: Counting objects:  96% (55/57)\u001b[K\r",
      "remote: Counting objects:  98% (56/57)\u001b[K\r",
      "remote: Counting objects: 100% (57/57)\u001b[K\r",
      "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Total 10153 (delta 25), reused 39 (delta 16), pack-reused 10096\u001b[K\n",
      "Receiving objects: 100% (10153/10153), 236.95 MiB | 15.74 MiB/s, done.\n",
      "Resolving deltas: 100% (50/50), done.\n",
      "Checking out files: 100% (10108/10108), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/joanby/deeplearning-az.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQdUNEVLuaYV"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLnJi3RNuZF8"
   },
   "outputs": [],
   "source": [
    "# Haremos un sistema de recomendación como el que podría utilizar Netflix o algun supermercado en la recomendación de productos\n",
    "# En este caso haremos un sistema que prediga si a un usuario le gustará o no una película con RBM, y con AE haremos uno que prediga la calificación del usuario a la película (ambas sobre las películas que no vieron) (el primero tendrá una salida binaria, mientras que el segundo usará una clasificación de salida del 1-5, con una predicción más sólida)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn # para crear redes neuronales\n",
    "import torch.nn.parallel # para hacer calculos en paralelo\n",
    "import torch.optim as optim # para minimizar nuestro error\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UL5sXo36uwOt"
   },
   "source": [
    "# Importar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bb-oWK50uyV4"
   },
   "outputs": [],
   "source": [
    "# Para RBM y AE usaremos el mismo dataset, uno de valoraciones de clientes sobre películas\n",
    "# Hay un PDF en la carpeta que explica más a detalle la teoría y práctica de RBM (recordar que queremos minimizar la energía de un estado del sistema, que es lo mismo que maximizar la probabilidad del mismo con Divergencia Contrastante)\n",
    "# Cargamos, del dataset de 1 millón de valoraciones: las películas, usuarios y puntajes\n",
    "movies = pd.read_csv(\"ml-1m/movies.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1') # así se guardan correctamente los df cuando vienen en formato .dat (header=None cuando en el archivo no hay encabezado de las columnas y ver encoding que se usó para realizar el dataset)\n",
    "users  = pd.read_csv(\"ml-1m/users.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings  = pd.read_csv(\"ml-1m/ratings.dat\", sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "# Sobre ratings particularmente es que vamos a dividir en train/test, ya que es en base a este dataset que vamos a crear el algoritmo, los otros son para luego tener una referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                   1                             2\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "...    ...                                 ...                           ...\n",
      "3878  3948             Meet the Parents (2000)                        Comedy\n",
      "3879  3949          Requiem for a Dream (2000)                         Drama\n",
      "3880  3950                    Tigerland (2000)                         Drama\n",
      "3881  3951             Two Family House (2000)                         Drama\n",
      "3882  3952               Contender, The (2000)                Drama|Thriller\n",
      "\n",
      "[3883 rows x 3 columns]\n",
      "---------------------------------------------------------------------------\n",
      "         0  1   2   3      4\n",
      "0        1  F   1  10  48067\n",
      "1        2  M  56  16  70072\n",
      "2        3  M  25  15  55117\n",
      "3        4  M  45   7  02460\n",
      "4        5  M  25  20  55455\n",
      "...    ... ..  ..  ..    ...\n",
      "6035  6036  F  25  15  32603\n",
      "6036  6037  F  45   1  76006\n",
      "6037  6038  F  56   1  14706\n",
      "6038  6039  F  45   0  01060\n",
      "6039  6040  M  25   6  11106\n",
      "\n",
      "[6040 rows x 5 columns]\n",
      "---------------------------------------------------------------------------\n",
      "            0     1  2          3\n",
      "0           1  1193  5  978300760\n",
      "1           1   661  3  978302109\n",
      "2           1   914  3  978301968\n",
      "3           1  3408  4  978300275\n",
      "4           1  2355  5  978824291\n",
      "...       ...   ... ..        ...\n",
      "1000204  6040  1091  1  956716541\n",
      "1000205  6040  1094  5  956704887\n",
      "1000206  6040   562  5  956704746\n",
      "1000207  6040  1096  4  956715648\n",
      "1000208  6040  1097  4  956715569\n",
      "\n",
      "[1000209 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(movies) # hay 3882 películas. El identificador de la película está en la primera columna, en la segunda el nombre y en la tercera su género/categoría\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(users) # hay 6040 usuarios. El identificador de los usuarios está en la primera columna, en la segunda su género, la tercera es la edad, la cuarta indica la ocupación del usuario y la quinta es el código postal de las personas\n",
    "print('---------------------------------------------------------------------------')\n",
    "print(ratings) # hay 1000209 valoraciones. La primera columna indica el identificador del usuario que emitió la valoración, la segunda columna sobre qué película emitió la valoración (identificador de la película), la tercera el puntaje/valoración otorgado a la película (1-5) y la cuarta es una referencia temporal sobre cuando fue que se emitió la valoración (poco importante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7MOlL4xvzPF"
   },
   "source": [
    "# Preparar el conjunto de entrenamiento y el conjunto de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frkm18WQv0tf"
   },
   "outputs": [],
   "source": [
    "# Vamos a tomar para esto el set de datos de 100.000 valoraciones, en donde hay 5 conjuntos de entrenamiento (u.base) y 5 conjuntos de test (u.test) para hacer k-fold cross validation\n",
    "# Esto nos servirá para entrenar hacia la NN, pero nosotros no usaremos validación cruzada, sino que sólo tomaremos u1.base y u1.test\n",
    "training_set = pd.read_csv(\"ml-100k/u1.base\", sep = \"\\t\", header = None) # para transformar en df usamos tabulador como separador (como no tiene nombre de columna el dataset le ponemos header=None)\n",
    "training_set = np.array(training_set, dtype = \"int\") # para Pytorch necesito arrays\n",
    "test_set = pd.read_csv(\"ml-100k/u1.test\", sep = \"\\t\", header = None)\n",
    "test_set = np.array(test_set, dtype = \"int\")\n",
    "# training_set incluye el 80% del conjunto de 100.000 valoraciones (usuarios, películas, valoración y referencia de tiempo), mientras que test_set el 20% restante (con misma disposición de columnas)\n",
    "# Este dataset pequeño de 100k lo usaremos para crear la Máquina de Boltzmann Reducida, intentando predecir si al usuario le gustará o no una película no vista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IeQfD-bwE8K"
   },
   "source": [
    "# Obtener el número de usuarios y de películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9SXaa1ZwGKa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "----\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "# Necesitamos obtener el número de usuarios y películas, para convertir el set de train y test en matrices, donde las filas serán los usuarios, las columnas las películas y las celdas las valoraciones de los usuarios sobre cada películas\n",
    "# Tanto para k-fold como para div por porcentajes, tendríamos que encontrar el máximo en los conjuntos de entrenamiento y de test que sean mayores a los otros conjuntos\n",
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:,0]))) # el num de usuario más grande del conjunto de train comparado con el más grande de test, quedándome con el más grande de ambos (usuarios en columna 0)\n",
    "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1]))) # el num de película más grande del conjunto de train comparado con el más grande de test, quedándome con el más grande de ambos (películas en columna 1)\n",
    "# Si hicieramos k-fold, agregar los otros 4 conjuntos en cada fila\n",
    "\n",
    "print(nb_users) # existen 943 usuarios (tomando train y test)\n",
    "print('----')\n",
    "print(nb_movies) # existen 1682 películas (tomando train y test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QixyuDRHxdDD"
   },
   "source": [
    "# Convertir los datos en un array X[u,i] con usuarios u en fila y películas i en columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHHL6CaJxkMM"
   },
   "outputs": [],
   "source": [
    "# Necesitamos esta estructura de datos para BM y AE\n",
    "def convert(data): # hacemos una función para hacer que las filas sean los usuarios y las columnas películas (conjunto de datos a transformar)\n",
    "    new_data = [] # matriz final (lo hago como lista de listas)\n",
    "    for id_user in range(1, nb_users+1): # itero sobre los usuarios (empieza desde el 1 incluyendo el último con el +1) \n",
    "        id_movies = data[:, 1][data[:, 0] == id_user] # me quedo con los id de las películas valoradas por ese usuario (segunda columna) (usamos el segundo corchete para filtrar que pertenezca el id de la película al usuario actual en el for)\n",
    "        id_ratings = data[:, 2][data[:, 0] == id_user] # me quedo con los puntajes de valoración realizados por ese usuario (tercera columna) (usamos el segundo corchete para filtrar que pertenezca la valoración al usuario actual en el for)\n",
    "        ratings = np.zeros(nb_movies) # inicializo una lista de 0 con las valoraciones del usuario del tamaño del número de películas total del dataset (suponemos que no vió ninguna inicialmente)\n",
    "        ratings[id_movies-1] = id_ratings # agregamos las valoraciones del usuario en ratings guiándonós de los índices de las películas -1 (que van del 1 al 1682), para que la película 1 vaya en la posición 0 de nuestra lista (y también incluya a la última película)\n",
    "        new_data.append(list(ratings)) # empalmamos la información de cada usuario (ratings) en la nueva matriz que recopile todos los usuarios (new_data)\n",
    "    return new_data # devolvemos el nuevo conjunto de datos\n",
    "# Hay 1682 columnas pertenecientes a la cantidad de usuarios que querramos analizar sus valoraciones (en caso de que las halla visto del 1-5, sino le pongo un 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLuyXa0Zxm9o"
   },
   "outputs": [],
   "source": [
    "# Convertimos al set de entrenamiento y test en la matriz con filas de usuarios y columnas de películas (mostrar el set transformado requiere mucha RAM por la cantidad de columnas y filas) \n",
    "# (Como si fuera un array de un csv)\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nIyS995x0PE"
   },
   "source": [
    "\n",
    "# Convertir los datos a tensores de Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JWlCORox0uf"
   },
   "outputs": [],
   "source": [
    "# Tensores son matrices que contienen elementos de un solo tipo de dato (matriz multidimensional). Debemos transformarlas para ingresar a la RBM\n",
    "training_set = torch.FloatTensor(training_set) # lo convertimos en un tensor de float\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeleljVhx3mx"
   },
   "source": [
    "# Convertir las valoraciones a valores binarios 1 (Me gusta) o 0 (No me gusta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vceBGxIVx5Qu"
   },
   "outputs": [],
   "source": [
    "# Como en RBM vamos a trabajar solo con 'Me Gusta' y 'No Me gusta' (valoraciones binarias), adaptamos las valoraciones originales de los usuarios que han emitido del 1-5 y ponemos un -1 sobre las no valoradas\n",
    "training_set[training_set == 0] = -1 # a las películas no visualizadas por el usuario le asgnamos un valor -1 (acordarse que inicialmente le habiamos puesto un 0 a las no vistas por el usuario)\n",
    "training_set[training_set == 1] = 0 # Pytorch no acepta un OR en la condición\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1 # a las valoraciones 3, 4 y 5 le asignamos un 1 (Me gusta), mientras que a las 1 y 2 le asignamos un 0 (No me gusta)\n",
    "# Si queremos brindar una salida binaria (predecir si al usuario le gustará (1) o no (0) una película, debemos tener entradas del mismo tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BeI34Q_x8o4"
   },
   "outputs": [],
   "source": [
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alN1pOH1x_Az"
   },
   "source": [
    "# Crear la arquitectura de la Red Neuronal (Modelo Probabilistico Gráfico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6WPiBsmwx_h-"
   },
   "outputs": [],
   "source": [
    "# CON ESPECIFICAR EL NÚMERO DE NODOS VISIBLES Y OCULTOS PODEMOS ENTRENAR CUALQUIER RBM (USANDO ESTA FUNCIÓN)\n",
    "# Recordar que es un modelo No Supervisado (no tenemos etiquetas sobre la variable a predecir, sino que es más difusa y particular la predicción)\n",
    "# Creamos una clase (POO) de la arquitectura RBM, conectando los nodos ocultos con un Modelo Probabilístico Gráfico (conecto en forma de grafo) (creamos objetos de esa clase particular)\n",
    "class RBM(): # a partir de una distribución de Bernoulli, que predice un resultado binario (éxito o fracaso)\n",
    "    \n",
    "    def __init__(self, nv, nh): # constructor, para inicializar la RBM (self: guardarmos aquí las variables locales para luego usarlas, nv: num de nodos visibles, nh: num de nodos ocultos). El método __init__ inicializará los pesos de las capas conectando todos con todos (incluso también con el término independiente)\n",
    "        self.W = torch.randn(nh, nv) # inicializo pesos (que relacionan un nodo de la capa visible con uno de la capa oculta con valores al azar pequeño pero no nulos, que se distribuyan normal estándar con randn). Tensor (matriz) de tamaño nh x nv\n",
    "        self.a = torch.randn(1, nh) # inicializo términos independientes (sesgo: el valor del nodo oculto conociendo el visible) de los nodos ocultos. Vector 1 x nh con inicialización random dist normal estandarizada (1° dim con num de elementos a entrenar y 2° dim correspondiente al sesgo, aclaramos dim adicional)\n",
    "        self.b = torch.randn(1, nv) # inicializo términos independientes de los nodos visibles de la misma forma con el tensor bidimensional al igual que arriba\n",
    "    \n",
    "    # Como vamos a tomar en x mini_batches (entrenamiento por bloques), requiero expansión de los términos independientes acorde al tamaño del mismo (#wx = mini_batch_size x nh, #x = mini_batch_size x nv)\n",
    "    # A partir de los valores de las capas visibles, vemos si se activan o no los nodos de las capas ocultas (con muestreo de Gibbs para converger rápidamente)\n",
    "    # x: entradas, relacionadas a las películas\n",
    "    def sample_h(self, x): # muestreo/calculo de las probabilidades de activación de los nodos de la capa oculta, conociendo los valores de los nodos visibles (función de activación sigmoidea) (con muestro de Gibbs para aproximar los gradientes de prob) (x: los valores de la capa visible, valoraciones de usuario)         \n",
    "        wx = torch.mm(x, self.W.t()) # para cada nodo oculto voy a calcular la prob de que se active, para luego con esa prob realizar un muestreo con prob de Bernoulli (para ver si lo activaría o no)(mm: matrix multiplication y t para tomar la transpuesta de los pesos)\n",
    "        activation = wx + self.a.expand_as(wx) # Obtenemos w.x + a(pesos por neuronas + el sesgo de la capa oculta), expandimos al tamaño del mini_batch\n",
    "        p_h_given_v = torch.sigmoid(activation) # Aplicamos la función sigmoide que activará el nodo oculto (obteniendo probabilidades entre 0 y 1 de que el nodo se active según los nodos de entrada) (prob de activarse nodos ocultos relacionados con los favoritismos del usuario serán elevadas)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v) # devolvemos no solo las probabilidades de los nodos ocultos conociendo los visibles, sino también una muestra Bernoulli con respecto a los nodos ocultos, que me mostrará cuales son los que activará (genero un vector con 0 y 1 a partir de que cada nodo oculto se active o no)\n",
    "\n",
    "    # (tamaños: #wy = mini_batch_size x nv, #y = mini_batch_size x nh)\n",
    "    # A partir de los valores (prob de activaciones) de los nodos ocultos, vemos si se activan o no se activan los valores de la capa visible (otro muestreo de Gibbs para converger rápidamente)\n",
    "    # y: lo que viene de la capa oculta\n",
    "    def sample_v(self, y): # muestreo de las probabilidades de los nodos de la capa visible, para luego concatenarlos a partir de los nodos de la capa oculta (prob condicionada: sabiendo los nodos de la capa visible, cuales son los de la oculta que influyen y viceversa relación)           \n",
    "        wy = torch.mm(y, self.W) # no hace falta tomar la transpuesta de los pesos\n",
    "        activation = wy + self.b.expand_as(wy) # sumamos los términos independientes de la capa visible expandidos acorde al mini_batch (entrenamiento por bloques)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h) # vemos cuales de los nodos visibles deben activarse con Bernoulli (muestra aleatoria) dadas las prob de activaciones de los nodos ocultos (que películas recomendar dadas las activaciones de los nodos ocultos para cada usuario, infiriendo si le gustará o no)\n",
    "\n",
    "# Usamos Divergencia Contrastante para aproximar el gradiente del logaritmo de la probabilidad (optimizar pesos para maximizar probabilidad del estado) \n",
    "# En vez de seguir la dirección del gradiente, pasando a través de diversos estados, aproximamos para que el estado actual sea el de mayor probabilidad con CD (ajustando los pesos en tal dirección con cadena de Gibbs en k-pasos de CD)        \n",
    "# Creamos el método de entrenamiento del algoritmo    \n",
    "    def train(self, v0, vk, ph0, phk): # v0: calificación original que han dado los usuarios (nodos visibles originales), vk: nodos visibles despues de k-pasos (despues de k idas-vueltas de CD), ph0: probabilidades en la primera iteración de los nodos ocultos dados los nodos visibles originales, phk: probabilidades de los nodos ocultos despues de k-iteraciones de CD  \n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t() # actualizamos los pesos (tomando el valor antiguo de los pesos y agregándole el producto de la prob de activación de v0 * ph0 - el producto de vk * phk). Primera actualización de la CD que actualiza los valores de los pesos\n",
    "        self.b += torch.sum((v0 - vk), 0) # actualizamos los sesgos (t.i)  de nodos visibles (valoración inicial del usuario - valoración que el algoritmo decide despues de k-iteraciones). Agregamos el 0 para mantener el formato del tensor en 2D y no nos salte error. Ajustamos los sesgos visibles con los valores visibles modificados\n",
    "        self.a += torch.sum((ph0 - phk), 0) # actualizamos los sesgos (t.i) con prob de act de nodos ocultos dados los nodos visibles (prob de que se activen los oscultos sabiendo la prob del original - prob de que se activen los ocultos conocidos los valores de la iteración k-ésima). Ajustamos los sesgos ocultos con las restas de las prob de los ocultos dados los visibles. Agregamos el 0 para mantener tensor 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos la RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "godGaYh9x__c"
   },
   "outputs": [],
   "source": [
    "# Inicialmente para crear la RBM, solo necesitamos saber el número de nodos visibles y el número de nodos ocultos\n",
    "nv = len(training_set[0]) # nodos visibles: cantidad de columnas en el dataset (películas)\n",
    "nh = 100 # nodos ocultos: a determinar (de 1682 nodos visibles, tenemos que decirle a la RBM la cantidad de correlaciones/características que encuentre) (probamos con 100, si vemos poca capacidad de predicción aumentamos con GridSearch)\n",
    "batch_size = 100 # tamaño del bloque de aprendizaje (actualizaremos los pesos luego de cada bloque introducido) (si ponemos 1 se actualiza dato a dato, mientras mayor sea menos tarda la convergencia, podemos usar tmb GridSearch)\n",
    "\n",
    "rbm = RBM(nv, nh) # creamos un objeto de la clase con nuestros valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTXM23qRyHhu"
   },
   "source": [
    "# Entrenar la RBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "4mKKUQs5yExt",
    "outputId": "95603e87-f89f-4d53-fe9c-1e133e5610bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: tensor(0.3402)\n",
      "Epoch: 2, Loss: tensor(0.2320)\n",
      "Epoch: 3, Loss: tensor(0.2500)\n",
      "Epoch: 4, Loss: tensor(0.2494)\n",
      "Epoch: 5, Loss: tensor(0.2487)\n",
      "Epoch: 6, Loss: tensor(0.2484)\n",
      "Epoch: 7, Loss: tensor(0.2475)\n",
      "Epoch: 8, Loss: tensor(0.2483)\n",
      "Epoch: 9, Loss: tensor(0.2477)\n",
      "Epoch: 10, Loss: tensor(0.2458)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10 # definimos el número de épocas (como el número de datos no es muy elevado y la predicción es binaria, ponemos pocas) (podemos subirla si no vemos buenos resultados)\n",
    "for epoch in range(1, nb_epoch+1): # for para cada época \n",
    "    training_loss = 0 # inicializamos la variable para cuantificar la pérdida de la función de pérdida que mida el error (usaremos RSME para AE y MAE, por tener solo 0 y 1, para RBM) \n",
    "    s = 0. # contador de observaciones (debremos normalizar el error por el número total de obs predichas, sacando el error relativo y asignándole así contexto al mismo) (ponemos 0. para inicializarlo como decimal)\n",
    "    # Comenzamos el entrenamiento real (llamando al sample_h, sample_v y train cuando tengamos un usuario/bloque de usuarios para tener neuronas activadas de la capa oculta, luego en base a ellas las activadas de la capa visible y entrenar en base a ese resultado)\n",
    "    # CD solo necesita la valoración inicial y la de luego de k-pasos, y las prob de activar un nodo oculto al principio y luego de k-pasos (en nuestro caso los usuarios los necesitamos en bloques)\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size): # for para recorrer a los usuarios en bloques (va del 0 hasta el dato con el q se puede tomar el último bloque avanzando según el tamaño del batch_size) (si lo hicieramos de 1 en 1 no agregar la 3ra parte del for)\n",
    "        vk = training_set[id_user:id_user+batch_size] # tomamos las valoraciones de los 100 usuarios del bloque para entrenar (a estas valoraciones las iremos actualizando a medida que apliquemos el muestro de Gibbs en k-pasos)\n",
    "        v0 = training_set[id_user:id_user+batch_size] # tomamos las valoraciones de los 100 usuarios del bloque para entrenar (las valoraciones iniciales siempre serán las mismas) (las usaremos para contrastar el error de vk respecto a las valoraciones iniciales)\n",
    "        ph0,_ = rbm.sample_h(v0) # prob de q se active un nodo oculto conociendo las entradas (valoraciones) originales (usamos sample_h para que nos devuelva prob de activar nodo oculto a partir de valores de entrada originales, v0) (ponemos ,_ para indicar que el segundo parámetro de return no me interesa)\n",
    "        # Lo que hace el algoritmo es un muestreo de Gibbs (camino ida y vuelta de los nodos visibles a los ocultos y viceversa). Intentaremos en cada ida y vuelta acercarnos a las buenas clasificaciones que queremos pronosticar\n",
    "        # Iremos activando nodos ocultos según prob Bernoulli\n",
    "        for k in range(10): # bucle que ejecute la cadena de Gibbs durante k-pasos del muestreo aleatorio o 'random walk' (elijo 10 iteraciones aleatorias del algoritmo)\n",
    "            _,hk = rbm.sample_h(vk) # buscamos en este caso el segundo parámetro (nodos ocultos que se activen), pasándole los valores del paso inmediatamente anterior (vk) (los nodos ocultos que se activan en el paso k-ésimo de la CD)\n",
    "            _,vk = rbm.sample_v(hk) # a partir de los nodos ocultos que se acaban de activar debo actualizar los nodos visibles. Así culminaría la primera ida y vuelta del muestreo de Gibbs hacia la convergencia (hasta k=10)\n",
    "            # a partir del la activación de los nodos ocultos en k(10) pasos del muestreo de Gibbs, calculará las activaciones de los nodos visibles, tendiendo a la convergencia de la calificación predicha por el algoritmo\n",
    "            vk[v0 < 0] = v0[v0 < 0] # congelamos (mantenemos los valores iniciales) los nodos visibles que originalmente valían -1 (películas no vistas) para que no sean actualizados. Los necesitaré predecir al final del algoritmo, ahora estamos entrenando nodos ocultos con la información que ya conocemos (películas vistas)\n",
    "        phk,_ = rbm.sample_h(vk) # sacamos el phk tomando vk (últimos valores conocidos de los nodos visibles luego de k-pasos) que nos falta para actualizar pesos (usar función train)\n",
    "        rbm.train(v0, vk, ph0, phk) # actualizamos los term indeps y pesos (valoraciones originales de usuarios, valoraciones luego de k pasos de CD, prob iniciales de act de nodos ocultos y prob de act de nodos ocultos luego de k-pasos de CD).\n",
    "        # Así se maximizará la prob, asignándole más pesos a los nodos ocultos relevantes para las clasificaciones de películas, acercándonos a las clasificaciones reales hechas por los usuarios respecto a las películas vistas\n",
    "        # Incrementamos el error tomando (MAE para clas binaria) la media absoluta entre la diferencia de la calificación original (v0 cuando no sea -1, solo las vistas) con respecto calificación predicha luego de k-pasos (vk cuando no sea -1, solo las vistas) \n",
    "        training_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0])) # cuanto de adecuación a las valoraciones iniciales estamos ganando por época (medida del error) (vemos si los nuevos pesos me dan valores dif de nodos visibles activados, aproximándose a los originales)\n",
    "        s += 1. # actualizamos el contador de observaciones, para obtener luego el error (MAE) relativo/normalizado \n",
    "    print(\"Epoch: \"+str(epoch)+\", Loss: \"+str(training_loss/s)) # mostramos la época por la que vamos y el valor de la función de pérdida normalizado (contrarrestando el efecto de las iteraciones, para que no crezca con cada ejecucuón acumulándolo, sino yéndolo dividiendo por el num de obs)\n",
    "# Como vemos, el valor de la función de pérdida tiende a 0.25, lo que significa que nuestro algoritmo se ajusta al set de entrenamiento logrando predecir correctamente 3 de cada 4 observaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUbXMjpsyMJg"
   },
   "source": [
    "# Testear la RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lPdWRxtLyKV2",
    "outputId": "8fac3d08-0f8e-412c-dc5d-8c8b12d2dd0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss: tensor(0.2044)\n",
      "Testing Loss: tensor(0.2158)\n",
      "Testing Loss: tensor(0.2593)\n",
      "Testing Loss: tensor(0.2445)\n",
      "Testing Loss: tensor(0.2789)\n",
      "Testing Loss: tensor(0.2638)\n",
      "Testing Loss: tensor(0.2509)\n",
      "Testing Loss: tensor(0.2411)\n",
      "Testing Loss: tensor(0.2254)\n",
      "Testing Loss: tensor(0.2195)\n",
      "Testing Loss: tensor(0.2223)\n",
      "Testing Loss: tensor(0.2198)\n",
      "Testing Loss: tensor(0.2289)\n",
      "Testing Loss: tensor(0.2289)\n",
      "Testing Loss: tensor(0.2454)\n",
      "Testing Loss: tensor(0.2389)\n",
      "Testing Loss: tensor(0.2575)\n",
      "Testing Loss: tensor(0.2503)\n",
      "Testing Loss: tensor(0.2476)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2562)\n",
      "Testing Loss: tensor(0.2594)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2488)\n",
      "Testing Loss: tensor(0.2400)\n",
      "Testing Loss: tensor(0.2411)\n",
      "Testing Loss: tensor(0.2445)\n",
      "Testing Loss: tensor(0.2411)\n",
      "Testing Loss: tensor(0.2409)\n",
      "Testing Loss: tensor(0.2421)\n",
      "Testing Loss: tensor(0.2443)\n",
      "Testing Loss: tensor(0.2448)\n",
      "Testing Loss: tensor(0.2465)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2574)\n",
      "Testing Loss: tensor(0.2579)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2564)\n",
      "Testing Loss: tensor(0.2556)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2501)\n",
      "Testing Loss: tensor(0.2501)\n",
      "Testing Loss: tensor(0.2481)\n",
      "Testing Loss: tensor(0.2495)\n",
      "Testing Loss: tensor(0.2466)\n",
      "Testing Loss: tensor(0.2439)\n",
      "Testing Loss: tensor(0.2482)\n",
      "Testing Loss: tensor(0.2487)\n",
      "Testing Loss: tensor(0.2466)\n",
      "Testing Loss: tensor(0.2465)\n",
      "Testing Loss: tensor(0.2481)\n",
      "Testing Loss: tensor(0.2477)\n",
      "Testing Loss: tensor(0.2499)\n",
      "Testing Loss: tensor(0.2493)\n",
      "Testing Loss: tensor(0.2500)\n",
      "Testing Loss: tensor(0.2492)\n",
      "Testing Loss: tensor(0.2494)\n",
      "Testing Loss: tensor(0.2476)\n",
      "Testing Loss: tensor(0.2509)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2511)\n",
      "Testing Loss: tensor(0.2482)\n",
      "Testing Loss: tensor(0.2473)\n",
      "Testing Loss: tensor(0.2458)\n",
      "Testing Loss: tensor(0.2455)\n",
      "Testing Loss: tensor(0.2447)\n",
      "Testing Loss: tensor(0.2437)\n",
      "Testing Loss: tensor(0.2429)\n",
      "Testing Loss: tensor(0.2411)\n",
      "Testing Loss: tensor(0.2436)\n",
      "Testing Loss: tensor(0.2429)\n",
      "Testing Loss: tensor(0.2409)\n",
      "Testing Loss: tensor(0.2433)\n",
      "Testing Loss: tensor(0.2448)\n",
      "Testing Loss: tensor(0.2434)\n",
      "Testing Loss: tensor(0.2457)\n",
      "Testing Loss: tensor(0.2455)\n",
      "Testing Loss: tensor(0.2461)\n",
      "Testing Loss: tensor(0.2446)\n",
      "Testing Loss: tensor(0.2444)\n",
      "Testing Loss: tensor(0.2454)\n",
      "Testing Loss: tensor(0.2454)\n",
      "Testing Loss: tensor(0.2460)\n",
      "Testing Loss: tensor(0.2461)\n",
      "Testing Loss: tensor(0.2452)\n",
      "Testing Loss: tensor(0.2445)\n",
      "Testing Loss: tensor(0.2449)\n",
      "Testing Loss: tensor(0.2452)\n",
      "Testing Loss: tensor(0.2456)\n",
      "Testing Loss: tensor(0.2455)\n",
      "Testing Loss: tensor(0.2448)\n",
      "Testing Loss: tensor(0.2427)\n",
      "Testing Loss: tensor(0.2421)\n",
      "Testing Loss: tensor(0.2425)\n",
      "Testing Loss: tensor(0.2429)\n",
      "Testing Loss: tensor(0.2442)\n",
      "Testing Loss: tensor(0.2453)\n",
      "Testing Loss: tensor(0.2430)\n",
      "Testing Loss: tensor(0.2450)\n",
      "Testing Loss: tensor(0.2441)\n",
      "Testing Loss: tensor(0.2431)\n",
      "Testing Loss: tensor(0.2449)\n",
      "Testing Loss: tensor(0.2450)\n",
      "Testing Loss: tensor(0.2449)\n",
      "Testing Loss: tensor(0.2456)\n",
      "Testing Loss: tensor(0.2449)\n",
      "Testing Loss: tensor(0.2463)\n",
      "Testing Loss: tensor(0.2477)\n",
      "Testing Loss: tensor(0.2468)\n",
      "Testing Loss: tensor(0.2470)\n",
      "Testing Loss: tensor(0.2477)\n",
      "Testing Loss: tensor(0.2477)\n",
      "Testing Loss: tensor(0.2465)\n",
      "Testing Loss: tensor(0.2460)\n",
      "Testing Loss: tensor(0.2460)\n",
      "Testing Loss: tensor(0.2467)\n",
      "Testing Loss: tensor(0.2455)\n",
      "Testing Loss: tensor(0.2452)\n",
      "Testing Loss: tensor(0.2448)\n",
      "Testing Loss: tensor(0.2450)\n",
      "Testing Loss: tensor(0.2471)\n",
      "Testing Loss: tensor(0.2484)\n",
      "Testing Loss: tensor(0.2484)\n",
      "Testing Loss: tensor(0.2511)\n",
      "Testing Loss: tensor(0.2511)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2493)\n",
      "Testing Loss: tensor(0.2503)\n",
      "Testing Loss: tensor(0.2501)\n",
      "Testing Loss: tensor(0.2502)\n",
      "Testing Loss: tensor(0.2498)\n",
      "Testing Loss: tensor(0.2489)\n",
      "Testing Loss: tensor(0.2474)\n",
      "Testing Loss: tensor(0.2481)\n",
      "Testing Loss: tensor(0.2489)\n",
      "Testing Loss: tensor(0.2495)\n",
      "Testing Loss: tensor(0.2499)\n",
      "Testing Loss: tensor(0.2496)\n",
      "Testing Loss: tensor(0.2490)\n",
      "Testing Loss: tensor(0.2496)\n",
      "Testing Loss: tensor(0.2479)\n",
      "Testing Loss: tensor(0.2482)\n",
      "Testing Loss: tensor(0.2489)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2557)\n",
      "Testing Loss: tensor(0.2565)\n",
      "Testing Loss: tensor(0.2562)\n",
      "Testing Loss: tensor(0.2564)\n",
      "Testing Loss: tensor(0.2562)\n",
      "Testing Loss: tensor(0.2560)\n",
      "Testing Loss: tensor(0.2560)\n",
      "Testing Loss: tensor(0.2560)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2557)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2556)\n",
      "Testing Loss: tensor(0.2554)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2552)\n",
      "Testing Loss: tensor(0.2556)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2557)\n",
      "Testing Loss: tensor(0.2557)\n",
      "Testing Loss: tensor(0.2564)\n",
      "Testing Loss: tensor(0.2561)\n",
      "Testing Loss: tensor(0.2566)\n",
      "Testing Loss: tensor(0.2575)\n",
      "Testing Loss: tensor(0.2574)\n",
      "Testing Loss: tensor(0.2581)\n",
      "Testing Loss: tensor(0.2580)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2587)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2600)\n",
      "Testing Loss: tensor(0.2592)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2588)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2577)\n",
      "Testing Loss: tensor(0.2574)\n",
      "Testing Loss: tensor(0.2573)\n",
      "Testing Loss: tensor(0.2574)\n",
      "Testing Loss: tensor(0.2565)\n",
      "Testing Loss: tensor(0.2568)\n",
      "Testing Loss: tensor(0.2564)\n",
      "Testing Loss: tensor(0.2565)\n",
      "Testing Loss: tensor(0.2568)\n",
      "Testing Loss: tensor(0.2576)\n",
      "Testing Loss: tensor(0.2580)\n",
      "Testing Loss: tensor(0.2580)\n",
      "Testing Loss: tensor(0.2575)\n",
      "Testing Loss: tensor(0.2574)\n",
      "Testing Loss: tensor(0.2572)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2584)\n",
      "Testing Loss: tensor(0.2577)\n",
      "Testing Loss: tensor(0.2573)\n",
      "Testing Loss: tensor(0.2568)\n",
      "Testing Loss: tensor(0.2568)\n",
      "Testing Loss: tensor(0.2561)\n",
      "Testing Loss: tensor(0.2559)\n",
      "Testing Loss: tensor(0.2556)\n",
      "Testing Loss: tensor(0.2549)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2546)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2550)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2542)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2534)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2513)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2538)\n",
      "Testing Loss: tensor(0.2533)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2526)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2513)\n",
      "Testing Loss: tensor(0.2513)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2511)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2508)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2504)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2506)\n",
      "Testing Loss: tensor(0.2505)\n",
      "Testing Loss: tensor(0.2503)\n",
      "Testing Loss: tensor(0.2505)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2508)\n",
      "Testing Loss: tensor(0.2511)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2510)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2499)\n",
      "Testing Loss: tensor(0.2505)\n",
      "Testing Loss: tensor(0.2503)\n",
      "Testing Loss: tensor(0.2506)\n",
      "Testing Loss: tensor(0.2506)\n",
      "Testing Loss: tensor(0.2504)\n",
      "Testing Loss: tensor(0.2502)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2509)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2509)\n",
      "Testing Loss: tensor(0.2513)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2513)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2522)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2530)\n",
      "Testing Loss: tensor(0.2527)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2532)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2537)\n",
      "Testing Loss: tensor(0.2539)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2543)\n",
      "Testing Loss: tensor(0.2540)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2551)\n",
      "Testing Loss: tensor(0.2545)\n",
      "Testing Loss: tensor(0.2544)\n",
      "Testing Loss: tensor(0.2547)\n",
      "Testing Loss: tensor(0.2541)\n",
      "Testing Loss: tensor(0.2535)\n",
      "Testing Loss: tensor(0.2529)\n",
      "Testing Loss: tensor(0.2523)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2524)\n",
      "Testing Loss: tensor(0.2521)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2519)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2512)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2511)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2509)\n",
      "Testing Loss: tensor(0.2509)\n",
      "Testing Loss: tensor(0.2507)\n",
      "Testing Loss: tensor(0.2514)\n",
      "Testing Loss: tensor(0.2515)\n",
      "Testing Loss: tensor(0.2516)\n",
      "Testing Loss: tensor(0.2518)\n",
      "Testing Loss: tensor(0.2517)\n",
      "Testing Loss: tensor(0.2528)\n",
      "Testing Loss: tensor(0.2525)\n",
      "Testing Loss: tensor(0.2520)\n",
      "Testing Loss: tensor(0.2536)\n",
      "Testing Loss: tensor(0.2531)\n",
      "Testing Loss: tensor(0.2525)\n"
     ]
    }
   ],
   "source": [
    "# Vemos si nuestro modelo se comporta bien prediciendo para otros usuarios, y cuantificamos también la pérdida respecto a estos nuevos datos (comparar con rendimiento en train para ver si se produce Overffiting o Underffiting)\n",
    "# En MCMC (Monte Carlo Markov Chain) la valoración se va acercando a su valor real\n",
    "# No hay entrenamiento, por lo que no requerimos las épocas ni un bucle sobre ellas, ya que la predicción será solo 1 (sobre el conjunto de test) (Shift + Tab para indexar todo)\n",
    "testing_loss = 0 # pérdida en conjunto de test\n",
    "s = 0.\n",
    "for id_user in range(nb_users): # podemos eliminar el bucle que recorre por bloques, para predecir de 1 en 1 observación (elimino el batch_size como 3er elemento) (el bucle pasa por cada usuario)\n",
    "    v = training_set[id_user:id_user+1] # tomamos la valoración del individuo actual (estado inicial de la predicción) (mantenemos el conjunto de train, ya que el sistema comenzará con las entradas conocidas)\n",
    "    vt = test_set[id_user:id_user+1] # tomamos la valoración del individuo actual (estado de la predicción sobre las películas no vistas (-1) del conjunto de train luego de t-pasos a lo largo del tiempo, convergiendo a la pred de la RBM)\n",
    "    # MCMC tiene en cuenta que las prob no son las mismas (caminata aleatoria, que nos basta con dar solo 1 paso para elaborar una predicción aproximada, ya que hemos entrenado al algoritmo para que tienda a adecuarse a los datos) (un solo viaje de ida y vuelta con el muestreo de Gibbs)\n",
    "    if len(vt[vt>=0]) > 0: # bucle que pasa por todas las valoraciones de los usuarios de test, siempre que tengan por lo menos vista 1 película (para saber preferencias)\n",
    "        _,h = rbm.sample_h(v) # en un sólo paso, calculo los nodos ocultos que se activarían en base a los visibles del usuario (películas vistas y valoradas por el mismo)\n",
    "        _,v = rbm.sample_v(h) # volveríamos para ver los nodos visibles que se activan dados los nodos ocultos activados para el usuario\n",
    "        # Podemos agregar las 2 líneas de código anterior para dar otro paso en MCMC\n",
    "        testing_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0])) # actualizamos la función de pérdida, midiendo el error a partir de las diferencias entre las valoraciones que ya conocemos del usuario y las predichas por el modelo (no podemos medir el error con respecto a las películas que el usuario no vió, ya que no sabriamos su resultado)\n",
    "        s += 1. # normalizar el error de predicción\n",
    "        print(\"Testing Loss: \"+str(testing_loss/s)) # pérdida para cada usuario (efectividad en la predicción del RBM tomando al train)\n",
    "\n",
    "# Aca vemos el error de la predicción con respecto a las películas que el usuario ya vió (suponemos que será el mismo con respecto a las películas no vistas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si quisieramos usar RMSE en vez de DISTANCIA MEDIA para medir rendimiento, deberíamos cambiar la función de pérdida en train a esto:\n",
    "# train_loss += np.sqrt(torch.mean((v0[v0>=0] - vk[v0>=0])**2))\n",
    "# y en test a esto:\n",
    "# test_loss += np.sqrt(torch.mean((vt[vt>=0] - v[vt>=0])**2)) \n",
    "# Usando el RMSE, nuestra MBR obtendría un error alrededor de 0.46. Pero ten cuidado, aunque parece similar, no se debe confundir el RMSE y la distancia promedio. Un RMSE de 0.46 no significa que la distancia promedio entre la predicción y la verdad del dataset sea 0.46. En modo aleatorio terminaríamos con un RMSE de alrededor de 0.72. Un error de 0.46 corresponde al 75% de la predicción exitosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74763\n",
      "0.25237\n"
     ]
    }
   ],
   "source": [
    "# Así se comprueba que un 0.25 de Distancia Media del modelo se corresponde con un 75% de éxito aproximado en la predicción\n",
    "import numpy as np\n",
    "u = np.random.choice([0,1], 100000)\n",
    "v = np.random.choice([0,1], 100000)\n",
    "u[:50000] = v[:50000]\n",
    "print(sum(u==v)/float(len(u))) # -> obtendremos 0.75\n",
    "print(np.mean(np.abs(u-v))) # -> obtendremos 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En vt tendríamos las predicciones del modelo con respecto a las películas no vistas por cada usuario, las cuales servirán para recomendación\n",
    "torch.set_printoptions(precision=2, threshold=torch.inf) # establecer opciones de impresión: precisión de 2 decimales y mostrar el tensor completo\n",
    "vt\n",
    "# Probar usar predict también"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "rbm.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
